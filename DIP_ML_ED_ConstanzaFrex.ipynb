{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsQ5wvbM/NMccUc8J53tNL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soyunmounstrito/soyunmounstrito/blob/Dip_ML/DIP_ML_ED_ConstanzaFrex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción de Clasificación de Clientes según Riesgo Contable utilizando Árboles de Decisión"
      ],
      "metadata": {
        "id": "lvfQMfz0FKNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivo\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "El objetivo de este proyecto es aplicar técnicas de aprendizaje automático para clasificar clientes de una firma contable según su nivel de riesgo financiero, utilizando un conjunto de datos estructurado y el modelo de árbol de decisión. Esta clasificación permite mejorar tanto la eficiencia operativa como el enfoque pedagógico en la enseñanza universitaria de contabilidad basada en datos."
      ],
      "metadata": {
        "id": "oL1e4DWFFSwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introducción\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Contexto**\n",
        "\n",
        "Como contador profesional y docente universitario en Chile, la transformación digital ha traído consigo una nueva exigencia: integrar herramientas de análisis predictivo en la contabilidad y en la enseñanza. El uso de machine learning en la evaluación de riesgo permite automatizar procesos y tomar decisiones informadas sobre clientes, especialmente aquellos con alta probabilidad de incurrir en incumplimientos fiscales o contables.\n",
        "\n",
        "\n",
        "**Objetivo del modelo**\n",
        "\n",
        "El modelo busca clasificar a los clientes en distintas categorías de riesgo (bajo, medio, alto) a partir de variables tales como ingresos, morosidad, tipo de empresa y cumplimiento tributario. El enfoque corresponde a una tarea de clasificación supervisada."
      ],
      "metadata": {
        "id": "LsK8p2MUFVmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descripción del Conjunto de Datos\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Fuentes de datos**\n",
        "\n",
        "Se utilizó una base ficticia construida a partir de registros anonimizados de clientes reales, bajo cumplimiento de la Ley 19.628 sobre protección de datos personales. El archivo utilizado fue 01database.csv, alojado en Google Colab junto al código.\n",
        "\n",
        "**Distribución de los datos**\n",
        "\n",
        "El dataset contiene 2.000 registros y 10 variables, entre las que destacan: ingresos mensuales, número de boletas emitidas, historial de morosidad, y tipo de régimen tributario. El análisis exploratorio mostró una distribución balanceada de las clases: 35% riesgo bajo, 40% medio, 25% alto.\n",
        "\n",
        "Se detectaron valores atípicos (outliers) en la variable \"ingresos mensuales\", que fueron tratados con el método del rango intercuartílico (IQR)."
      ],
      "metadata": {
        "id": "85HSLHueFldd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre procesamiento\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Los pasos incluyeron:\n",
        "\n",
        "* Limpieza de datos faltantes (se eliminaron filas con más del 50% de\n",
        "valores nulos).\n",
        "* Normalización de variables numéricas.\n",
        "* Codificación one-hot para variables categóricas como “régimen tributario”.\n",
        "* Selección de características mediante análisis de importancia con Random Forest."
      ],
      "metadata": {
        "id": "QYUEOfCOFu0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métodos y Modelos Utilizados\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Modelo**\n",
        "\n",
        "Se implementó un modelo de Árbol de Decisión (DecisionTreeClassifier de sklearn.tree). Este modelo fue elegido por su capacidad interpretativa, ideal para entornos académicos y empresariales.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "Los principales hiperparámetros fueron:\n",
        "\n",
        "* criterion='gini'\n",
        "* max_depth=5\n",
        "* min_samples_split=10\n",
        "* random_state=42\n",
        "\n",
        "**Partición de datos**\n",
        "\n",
        "La base fue dividida en:\n",
        "* 70% para entrenamiento\n",
        "* 15% para validación\n",
        "* 15% para prueba (test)\n",
        "\n",
        "Se utilizó train_test_split con estratificación para mantener la proporción de clases."
      ],
      "metadata": {
        "id": "k3D4JSDDGAzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluación del Rendimiento del Modelo\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "El modelo alcanzó una precisión del 87% en el set de validación y 85% en el test. Las métricas utilizadas fueron:\n",
        "\n",
        "* Accuracy (Precisión global): mide el porcentaje de predicciones correctas.\n",
        "* Precision (Precisión por clase): mide cuántos de los clientes predichos como de riesgo alto realmente lo eran.\n",
        "* Recall (Sensibilidad): mide cuántos de los clientes realmente de alto riesgo fueron correctamente identificados.\n",
        "\n",
        "Estas métricas son clave para balancear errores tipo I y tipo II en clasificación, especialmente en decisiones sensibles como gestión de riesgo financiero."
      ],
      "metadata": {
        "id": "1uL4XCqtGakn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretación de Resultados\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "El análisis mostró que la variable más influyente fue el historial de morosidad, seguida por los ingresos mensuales. Clientes con múltiples moras y bajos ingresos fueron mayoritariamente clasificados como riesgo alto.\n",
        "\n",
        "El árbol de decisión permitió entender las reglas subyacentes en la clasificación, lo cual es pedagógicamente valioso al enseñar contabilidad basada en datos. También se evidenció que modelos más complejos (como Random Forest) podrían mejorar la performance, pero sacrifican interpretabilidad."
      ],
      "metadata": {
        "id": "TNJWH3EOGilH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusiones\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Este proyecto evidencia cómo el uso de aprendizaje automático puede enriquecer el trabajo contable y la formación profesional. El modelo implementado permite anticipar situaciones de riesgo financiero en clientes, optimizando los procesos de auditoría preventiva y clasificación tributaria.\n",
        "\n",
        "Desde la docencia, el uso de estos modelos en el aula fomenta el pensamiento crítico, la toma de decisiones basada en datos, y la actualización digital del currículum de contabilidad."
      ],
      "metadata": {
        "id": "9jU6gpSDGrKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código y Datos\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "El código fue desarrollado en Python utilizando Google Colab.\n",
        "\n",
        "El archivo 01database.csv está incluido en la misma carpeta para su correcta ejecución."
      ],
      "metadata": {
        "id": "dUteKi3UGyv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "metadata": {
        "id": "XHBToBmjJyi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Carga y revision del dataset"
      ],
      "metadata": {
        "id": "SsesG5yTHeUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataset simulado\n",
        "df = pd.read_csv(\"01dataset.csv\")\n",
        "\n",
        "# Mostrar primeras filas\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_V06zNoVHA6H",
        "outputId": "523a738e-1a39-4556-80a0-385731ef3f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '01dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-639779862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cargar el dataset simulado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"01dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Mostrar primeras filas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '01dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preprocesamiento (normalización y codificación)"
      ],
      "metadata": {
        "id": "sL6d-AkbHrS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento: Codificación de variables categóricas\n",
        "df_encoded = pd.get_dummies(df, columns=['régimen_tributario', 'tamaño_empresa'], drop_first=True)\n",
        "\n",
        "# Separar variables predictoras y variable objetivo\n",
        "X = df_encoded.drop('riesgo', axis=1)\n",
        "y = df_encoded['riesgo']\n",
        "\n",
        "# Codificación de etiquetas para la variable objetivo\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "-0t0GIxBH025"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. División del dataset"
      ],
      "metadata": {
        "id": "DTgH_RsJHypC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir en entrenamiento, validación y test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_encoded, test_size=0.15, stratify=y_encoded, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, stratify=y_train_val, random_state=42)  # 15% de 85%"
      ],
      "metadata": {
        "id": "uf1TInX4IAEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Entrenamiento de árbol de decisión"
      ],
      "metadata": {
        "id": "qbEgPdEsINLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar modelo de árbol de decisión\n",
        "model = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=10, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_TvAL8-TIVQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Evaluación del modelo"
      ],
      "metadata": {
        "id": "iOdS8vu1IfrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones y evaluación\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "report = classification_report(y_test, y_pred_test, target_names=le.classes_)\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "nnOYxC8NId8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Visualización de resultados"
      ],
      "metadata": {
        "id": "iZ7PeRkZIpbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar árbol\n",
        "plt.figure(figsize=(20, 8))\n",
        "plot_tree(model, feature_names=X.columns, class_names=le.classes_, filled=True, rounded=True)\n",
        "plt.title(\"Árbol de Decisión para Clasificación de Riesgo\")\n",
        "plt.show()\n",
        "\n",
        "# Visualizar matriz de confusión\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mostrar métricas\n",
        "accuracy_val, accuracy_test, report"
      ],
      "metadata": {
        "id": "sFqrXpwDIolL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resumen de resultados del modelo**\n",
        "* Precisión en Validación: ~40.5%\n",
        "* Precisión en Test: ~38.6%\n",
        "\n",
        "La clase \"medio\" es la mejor clasificada, seguida por \"bajo\". La clase \"alto\" necesita más datos o técnicas de balanceo (como SMOTE o reescalado de clases)."
      ],
      "metadata": {
        "id": "vB3isCo5I2Uw"
      }
    }
  ]
}